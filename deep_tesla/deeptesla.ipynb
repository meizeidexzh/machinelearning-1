{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: C:\\machinelearning\\epochs\\epoch01_front.mkv\n",
      "Shape:x = (9, 64, 64, 3) y = (9, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x280067147f0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niM0fCFQU/x/9Tn6dt0761wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x280067788d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import params,utils\n",
    "\n",
    "#按批次读取数据\n",
    "class ImgGenerator():\n",
    "    def __init__(self,img_path,batch_id,batch_size=None,input_shape=(224,224,3),train_ratio=0.9):\n",
    "        self.img_path = img_path\n",
    "        self.batch_id = batch_id\n",
    "        self.batch_size = batch_size\n",
    "        self.current_frame = 0\n",
    "        self.input_shape = input_shape\n",
    "        self.train_ratio = train_ratio\n",
    "        \n",
    "    def next_batch(self):\n",
    "        #标注处理\n",
    "        label_all = utils.get_human_steering(self.batch_id)\n",
    "        if(self.batch_size == None):\n",
    "            self.batch_size = len(label_all)\n",
    "            \n",
    "        label = utils.get_human_steering(self.batch_id)[self.current_frame:self.current_frame+self.batch_size]\n",
    "        labels = [[label[i]] for i in range(len(label))]\n",
    "        labels = np.array(labels)\n",
    "        #图像处理        \n",
    "        vid_path = utils.join_dir(params.data_dir, 'epoch{:0>2}_front.mkv'.format(self.batch_id))\n",
    "        print('Train:',vid_path)\n",
    "        cap = cv2.VideoCapture(vid_path)\n",
    "        nframe = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) - 2)\n",
    "        if( (self.current_frame+self.batch_size) > nframe):\n",
    "            self.batch_size = nframe - self.current_frame\n",
    "        images = []\n",
    "        for i in range(self.current_frame,self.current_frame+self.batch_size):\n",
    "            utils.cv2_goto_frame(cap,i) \n",
    "            ret, frame = cap.read()\n",
    "            if (ret == True):\n",
    "                shape = frame.shape\n",
    "                frame = frame[int(shape[0]/3):shape[0]-150, 0:shape[1]]\n",
    "                frame = cv2.resize(frame, (self.input_shape[0], self.input_shape[1]), interpolation=cv2.INTER_AREA)\n",
    "                frame = np.resize(frame, (self.input_shape[0], self.input_shape[1], self.input_shape[2]))\n",
    "                images.append(frame)\n",
    "                del frame\n",
    "        images = np.array(images)    \n",
    "        self.current_frame = utils.cv2_current_frame(cap)\n",
    "        cap.release()\n",
    "\n",
    "        return (images[:int(self.batch_size*self.train_ratio)],labels[:int(self.batch_size*self.train_ratio)],\n",
    "                images[int(self.batch_size*self.train_ratio):],labels[int(self.batch_size*self.train_ratio):])\n",
    "    \n",
    "#Test\n",
    "from matplotlib import pyplot \n",
    "%matplotlib inline\n",
    "img_path = params.data_dir\n",
    "input_shape=(64, 64, params.FLAGS.img_c)\n",
    "x_test,y_test,_,_ = ImgGenerator(img_path,'01',batch_size=10,input_shape=input_shape).next_batch()\n",
    "assert len(x_test)==len(y_test)\n",
    "index = 8\n",
    "print('Shape:x =',x_test.shape,'y =',y_test.shape)\n",
    "pyplot.imshow(x_test[index])\n",
    "pyplot.title('Angle:'+str(y_test[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#vgg16模型改造\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Input\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.layers import Lambda\n",
    "\n",
    "def vgg16_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    lambda_input = Lambda(lambda x:x/255.-0.5,name='Lambda')(inputs)\n",
    "    base_model = VGG16(include_top=False, weights='imagenet',input_tensor=lambda_input)\n",
    "    \n",
    "    #for layer in base_model.layers:\n",
    "    #    layer.trainable = False\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(512, activation='relu', name='fc1')(x)\n",
    "    x = Dropout(0.8,name='fc1_dropout')(x)\n",
    "    x = Dense(256, activation='relu', name='fc2')(x)\n",
    "    x = Dropout(0.8,name='fc2_dropout')(x)\n",
    "    x = Dense(64, activation='relu', name='fc3')(x)\n",
    "    x = Dropout(0.8,name='fc3_dropout')(x)\n",
    "    x = Dense(1,activation='tanh',name='output')(x)\n",
    "    \n",
    "    model = Model(inputs,x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input,Conv2D,Lambda,MaxPooling2D,Flatten,Dense\n",
    "def nvidia_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    x = Lambda(lambda x:x/255,name='Lambda')(inputs)\n",
    "    \n",
    "    x = Conv2D(24, (5, 5), activation='relu', padding='same', name='block1_conv1')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    x = Conv2D(36, (5, 5), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "    \n",
    "    x = Conv2D(48, (5, 5), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "    \n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(1164, activation='relu', name='fc1')(x)\n",
    "    x = Dense(100, activation='relu', name='fc2')(x)\n",
    "    x = Dense(50, activation='relu', name='fc3')(x)\n",
    "    x = Dense(10, activation='relu', name='fc4')(x)\n",
    "    x = Dense(1,name='output')(x)\n",
    "    \n",
    "    model = Model(inputs,x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Sequential,Convolution2D\n",
    "def nvidia_model2(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x:x/255, input_shape=input_shape))\n",
    "    model.add(Convolution2D(24,5,5,border_mode='valid', activation='relu', subsample=(2,2)))\n",
    "    model.add(Convolution2D(36,5,5,border_mode='valid', activation='relu', subsample=(2,2)))\n",
    "    model.add(Convolution2D(48,5,5,border_mode='valid', activation='relu', subsample=(2,2)))\n",
    "    model.add(Convolution2D(64,3,3,border_mode='valid', activation='relu', subsample=(1,1)))\n",
    "    model.add(Convolution2D(64,3,3,border_mode='valid', activation='relu', subsample=(1,1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1164, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (5, 5), padding=\"valid\", activation=\"relu\", strides=(2, 2))`\n",
      "  \"\"\"\n",
      "C:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(36, (5, 5), padding=\"valid\", activation=\"relu\", strides=(2, 2))`\n",
      "  \n",
      "C:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (5, 5), padding=\"valid\", activation=\"relu\", strides=(2, 2))`\n",
      "  import sys\n",
      "C:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"valid\", activation=\"relu\", strides=(1, 1))`\n",
      "  \n",
      "C:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"valid\", activation=\"relu\", strides=(1, 1))`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_5 (Lambda)            (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 30, 30, 24)        1824      \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 13, 13, 36)        21636     \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 5, 5, 48)          43248     \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 3, 3, 64)          27712     \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 1, 1, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1164)              75660     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               116500    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 329,079\n",
      "Trainable params: 329,079\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train: C:\\machinelearning\\epochs\\epoch01_front.mkv\n",
      "Train on 57 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "57/57 [==============================] - 1s 23ms/step - loss: 1.2753 - acc: 0.2632 - val_loss: 0.1429 - val_acc: 0.4286\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.2630 - acc: 0.2632 - val_loss: 0.1444 - val_acc: 0.4286\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.2579 - acc: 0.2632 - val_loss: 0.1451 - val_acc: 0.4286\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.2555 - acc: 0.2632 - val_loss: 0.1459 - val_acc: 0.4286\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.2528 - acc: 0.2632 - val_loss: 0.1470 - val_acc: 0.4286\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.2493 - acc: 0.2632 - val_loss: 0.1484 - val_acc: 0.4286\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.2446 - acc: 0.2632 - val_loss: 0.1502 - val_acc: 0.4286\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.2386 - acc: 0.2632 - val_loss: 0.1526 - val_acc: 0.4286\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.2309 - acc: 0.2632 - val_loss: 0.1559 - val_acc: 0.4286\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.2204 - acc: 0.2632 - val_loss: 0.1604 - val_acc: 0.4286\n",
      "Train: C:\\machinelearning\\epochs\\epoch01_front.mkv\n",
      "Train on 57 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2805 - acc: 0.0000e+00 - val_loss: 0.2862 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2845 - acc: 0.0000e+00 - val_loss: 0.2872 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2847 - acc: 0.0000e+00 - val_loss: 0.2850 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2822 - acc: 0.0000e+00 - val_loss: 0.2810 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2783 - acc: 0.0000e+00 - val_loss: 0.2765 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2742 - acc: 0.0000e+00 - val_loss: 0.2720 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2700 - acc: 0.0000e+00 - val_loss: 0.2679 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2664 - acc: 0.0000e+00 - val_loss: 0.2645 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2632 - acc: 0.0000e+00 - val_loss: 0.2615 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2604 - acc: 0.0000e+00 - val_loss: 0.2589 - val_acc: 0.0000e+00\n",
      "Train: C:\\machinelearning\\epochs\\epoch01_front.mkv\n",
      "Train on 57 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2586 - acc: 0.0000e+00 - val_loss: 0.2568 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2565 - acc: 0.0000e+00 - val_loss: 0.2549 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2546 - acc: 0.0000e+00 - val_loss: 0.2532 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2529 - acc: 0.0000e+00 - val_loss: 0.2519 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2515 - acc: 0.0000e+00 - val_loss: 0.2506 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2501 - acc: 0.0000e+00 - val_loss: 0.2485 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2478 - acc: 0.0000e+00 - val_loss: 0.2458 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2448 - acc: 0.0000e+00 - val_loss: 0.2423 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2410 - acc: 0.0000e+00 - val_loss: 0.2377 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2360 - acc: 0.0000e+00 - val_loss: 0.2320 - val_acc: 0.0000e+00\n",
      "Train: C:\\machinelearning\\epochs\\epoch01_front.mkv\n",
      "Train on 57 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1206 - acc: 0.4737 - val_loss: 0.2244 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1168 - acc: 0.4737 - val_loss: 0.2158 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1121 - acc: 0.4737 - val_loss: 0.2042 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1060 - acc: 0.4737 - val_loss: 0.1896 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0987 - acc: 0.4737 - val_loss: 0.1714 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0899 - acc: 0.4737 - val_loss: 0.1490 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0798 - acc: 0.4737 - val_loss: 0.1224 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0696 - acc: 0.4737 - val_loss: 0.0931 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0612 - acc: 0.4737 - val_loss: 0.0646 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0568 - acc: 0.4737 - val_loss: 0.0406 - val_acc: 0.0000e+00\n",
      "Train: C:\\machinelearning\\epochs\\epoch01_front.mkv\n",
      "Train on 57 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0830 - acc: 0.0000e+00 - val_loss: 0.3649 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0428 - acc: 0.0000e+00 - val_loss: 0.2153 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0237 - acc: 0.1228 - val_loss: 0.0965 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0462 - acc: 0.1228 - val_loss: 0.0683 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0570 - acc: 0.1228 - val_loss: 0.1017 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0405 - acc: 0.1228 - val_loss: 0.1655 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0303 - acc: 0.1228 - val_loss: 0.2275 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0314 - acc: 0.0000e+00 - val_loss: 0.2652 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0342 - acc: 0.0000e+00 - val_loss: 0.2731 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0337 - acc: 0.0000e+00 - val_loss: 0.2562 - val_acc: 0.0000e+00\n",
      "Train: C:\\machinelearning\\epochs\\epoch01_front.mkv\n",
      "Train on 57 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1614 - acc: 0.6491 - val_loss: 1.6572e-05 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1572 - acc: 0.3509 - val_loss: 5.2162e-04 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1541 - acc: 0.3509 - val_loss: 6.8264e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1515 - acc: 0.3509 - val_loss: 3.3201e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1497 - acc: 0.3509 - val_loss: 2.0298e-05 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1489 - acc: 0.3509 - val_loss: 1.2819e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1492 - acc: 0.6667 - val_loss: 6.5018e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1502 - acc: 0.6667 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1514 - acc: 0.6491 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1524 - acc: 0.6140 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Train: C:\\machinelearning\\epochs\\epoch01_front.mkv\n",
      "Train on 57 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5276 - acc: 0.1053 - val_loss: 0.3675 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5016 - acc: 0.1053 - val_loss: 0.4265 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4740 - acc: 0.1053 - val_loss: 0.4884 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.4513 - acc: 0.1053 - val_loss: 0.5458 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.4348 - acc: 0.1053 - val_loss: 0.5958 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4233 - acc: 0.1053 - val_loss: 0.6377 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.4156 - acc: 0.1053 - val_loss: 0.6718 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.4103 - acc: 0.1053 - val_loss: 0.6993 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.4068 - acc: 0.1053 - val_loss: 0.7212 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.4044 - acc: 0.1053 - val_loss: 0.7386 - val_acc: 0.0000e+00\n",
      "Train: C:\\machinelearning\\epochs\\epoch01_front.mkv\n",
      "Train on 57 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1965 - acc: 0.0000e+00 - val_loss: 0.1370 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1963 - acc: 0.0000e+00 - val_loss: 0.1330 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1907 - acc: 0.0000e+00 - val_loss: 0.1251 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1808 - acc: 0.0000e+00 - val_loss: 0.1137 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1667 - acc: 0.0000e+00 - val_loss: 0.0994 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1492 - acc: 0.0000e+00 - val_loss: 0.0826 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1287 - acc: 0.0000e+00 - val_loss: 0.0637 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1057 - acc: 0.0000e+00 - val_loss: 0.0438 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0812 - acc: 0.0000e+00 - val_loss: 0.0244 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0571 - acc: 0.0000e+00 - val_loss: 0.0084 - val_acc: 0.0000e+00\n",
      "Train: C:\\machinelearning\\epochs\\epoch01_front.mkv\n",
      "Train on 57 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.5874 - acc: 0.3333 - val_loss: 10.1850 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.5316 - acc: 0.3333 - val_loss: 9.8218 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.4096 - acc: 0.3333 - val_loss: 9.3859 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.2913 - acc: 0.3333 - val_loss: 8.9966 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.1972 - acc: 0.3333 - val_loss: 8.6852 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.1285 - acc: 0.3333 - val_loss: 8.4484 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.0797 - acc: 0.3333 - val_loss: 8.2708 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.0438 - acc: 0.3333 - val_loss: 8.1246 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.0149 - acc: 0.3333 - val_loss: 8.0098 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.9954 - acc: 0.3333 - val_loss: 7.9350 - val_acc: 0.0000e+00\n",
      "Train: C:\\machinelearning\\epochs\\epoch01_front.mkv\n",
      "Train on 57 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 22.0957 - acc: 0.0000e+00 - val_loss: 27.3354 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 21.9668 - acc: 0.0000e+00 - val_loss: 27.2114 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 21.8763 - acc: 0.0000e+00 - val_loss: 27.1672 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 21.8484 - acc: 0.0000e+00 - val_loss: 27.1426 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 21.8234 - acc: 0.0000e+00 - val_loss: 27.1058 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 21.7897 - acc: 0.0000e+00 - val_loss: 27.0603 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 21.7489 - acc: 0.0000e+00 - val_loss: 27.0035 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 21.6952 - acc: 0.0000e+00 - val_loss: 26.9218 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 21.6209 - acc: 0.0000e+00 - val_loss: 26.8085 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 21.5110 - acc: 0.0000e+00 - val_loss: 26.6462 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: C:\\machinelearning\\epochs\\epoch01_front.mkv\n",
      "Train on 57 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 20.0250 - acc: 0.0000e+00 - val_loss: 19.5595 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 19.7692 - acc: 0.0000e+00 - val_loss: 19.2309 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 19.3650 - acc: 0.0000e+00 - val_loss: 18.6894 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 18.7004 - acc: 0.0000e+00 - val_loss: 17.7892 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 17.5901 - acc: 0.0000e+00 - val_loss: 16.2929 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 15.7698 - acc: 0.0000e+00 - val_loss: 14.0317 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 13.0849 - acc: 0.0000e+00 - val_loss: 10.6782 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 9.2168 - acc: 0.0000e+00 - val_loss: 6.2032 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 4.3982 - acc: 0.0000e+00 - val_loss: 1.5626 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.4458 - acc: 0.0000e+00 - val_loss: 0.3033 - val_acc: 0.0000e+00\n",
      "Train: C:\\machinelearning\\epochs\\epoch01_front.mkv\n",
      "Train on 57 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.5455 - acc: 0.1404 - val_loss: 8.1151 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 3.2886 - acc: 0.0000e+00 - val_loss: 5.6216 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.4104 - acc: 0.1930 - val_loss: 1.6173 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2209 - acc: 0.1754 - val_loss: 0.1527 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.5991 - acc: 0.1579 - val_loss: 0.0087 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.1979 - acc: 0.1579 - val_loss: 0.0489 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.3327 - acc: 0.1579 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.0136 - acc: 0.1579 - val_loss: 0.0761 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5552 - acc: 0.0877 - val_loss: 0.5596 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.3192 - acc: 0.1404 - val_loss: 1.4586 - val_acc: 0.0000e+00\n",
      "Train: C:\\machinelearning\\epochs\\epoch01_front.mkv\n",
      "Train on 57 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 8.8674 - acc: 0.2456 - val_loss: 22.6218 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 4.6461 - acc: 0.2982 - val_loss: 10.9833 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.0548 - acc: 0.1053 - val_loss: 4.1787 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.1743 - acc: 0.0351 - val_loss: 1.4077 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 3.2706 - acc: 0.1930 - val_loss: 0.4970 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 4.1955 - acc: 0.2105 - val_loss: 0.2579 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 4.6086 - acc: 0.2105 - val_loss: 0.2761 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 4.5235 - acc: 0.2105 - val_loss: 0.5080 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 4.0872 - acc: 0.2105 - val_loss: 1.0735 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 3.5023 - acc: 0.0702 - val_loss: 2.1215 - val_acc: 0.0000e+00\n",
      "Train: C:\\machinelearning\\epochs\\epoch01_front.mkv\n",
      "Train on 57 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 6.3464 - acc: 0.0000e+00 - val_loss: 19.4904 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 6.1805 - acc: 0.0000e+00 - val_loss: 17.6705 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 4.9864 - acc: 0.0000e+00 - val_loss: 14.8399 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 3.5735 - acc: 0.0175 - val_loss: 12.0404 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.4581 - acc: 0.1754 - val_loss: 9.7398 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.7607 - acc: 0.2632 - val_loss: 8.0036 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.3943 - acc: 0.1404 - val_loss: 6.7378 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.2385 - acc: 0.0702 - val_loss: 5.8289 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.2000 - acc: 0.1053 - val_loss: 5.1760 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.2190 - acc: 0.1053 - val_loss: 4.7056 - val_acc: 0.0000e+00\n",
      "Train: C:\\machinelearning\\epochs\\epoch01_front.mkv\n",
      "Train on 57 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 5.6000 - acc: 0.0000e+00 - val_loss: 10.2443 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 5.0770 - acc: 0.0000e+00 - val_loss: 9.5262 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 4.5798 - acc: 0.0000e+00 - val_loss: 8.8670 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 4.1369 - acc: 0.0000e+00 - val_loss: 8.2875 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 3.7539 - acc: 0.0000e+00 - val_loss: 7.7887 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 3.4310 - acc: 0.0000e+00 - val_loss: 7.3613 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 3.1589 - acc: 0.0000e+00 - val_loss: 6.9976 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.9299 - acc: 0.0000e+00 - val_loss: 6.6818 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.7330 - acc: 0.0000e+00 - val_loss: 6.4088 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.5653 - acc: 0.0000e+00 - val_loss: 6.1723 - val_acc: 0.0000e+00\n",
      "Train: C:\\machinelearning\\epochs\\epoch01_front.mkv\n",
      "Train on 57 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 21.4180 - acc: 0.0000e+00 - val_loss: 23.6884 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 20.9324 - acc: 0.0000e+00 - val_loss: 23.0998 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 20.3855 - acc: 0.0000e+00 - val_loss: 22.5514 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 19.9002 - acc: 0.0000e+00 - val_loss: 22.0284 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 19.4329 - acc: 0.0000e+00 - val_loss: 21.5721 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 19.0290 - acc: 0.0000e+00 - val_loss: 21.1836 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 18.6860 - acc: 0.0000e+00 - val_loss: 20.8492 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 18.3892 - acc: 0.0000e+00 - val_loss: 20.5570 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 18.1300 - acc: 0.0000e+00 - val_loss: 20.3061 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 17.9126 - acc: 0.0000e+00 - val_loss: 20.1200 - val_acc: 0.0000e+00\n",
      "Train: C:\\machinelearning\\epochs\\epoch01_front.mkv\n",
      "Train on 57 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 24.6848 - acc: 0.0000e+00 - val_loss: 26.9469 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 24.5333 - acc: 0.0000e+00 - val_loss: 26.8042 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 24.3829 - acc: 0.0000e+00 - val_loss: 26.6298 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 24.2041 - acc: 0.0000e+00 - val_loss: 26.4165 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 23.9846 - acc: 0.0000e+00 - val_loss: 26.1703 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 23.7231 - acc: 0.0000e+00 - val_loss: 25.8729 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 23.4209 - acc: 0.0000e+00 - val_loss: 25.5888 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 23.1425 - acc: 0.0000e+00 - val_loss: 25.2901 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 22.8213 - acc: 0.0000e+00 - val_loss: 24.8911 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 22.3997 - acc: 0.0000e+00 - val_loss: 24.4040 - val_acc: 0.0000e+00\n",
      "Train: C:\\machinelearning\\epochs\\epoch01_front.mkv\n",
      "Train on 57 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 13.7006 - acc: 0.0000e+00 - val_loss: 17.2713 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 13.2311 - acc: 0.0000e+00 - val_loss: 16.6392 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 12.6531 - acc: 0.0000e+00 - val_loss: 15.8749 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 11.9631 - acc: 0.0000e+00 - val_loss: 14.9489 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 11.1180 - acc: 0.0000e+00 - val_loss: 13.8073 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 10.0852 - acc: 0.0000e+00 - val_loss: 12.3735 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 8.8086 - acc: 0.0000e+00 - val_loss: 10.6230 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 7.2652 - acc: 0.0000e+00 - val_loss: 8.5351 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 5.4721 - acc: 0.0000e+00 - val_loss: 6.1191 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 3.5103 - acc: 0.0000e+00 - val_loss: 3.5583 - val_acc: 0.0000e+00\n",
      "Train: C:\\machinelearning\\epochs\\epoch01_front.mkv\n",
      "Train on 57 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 3.1655 - acc: 0.0000e+00 - val_loss: 1.8772 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.9631 - acc: 0.0000e+00 - val_loss: 0.2047 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0612 - acc: 0.0000e+00 - val_loss: 0.3918 - val_acc: 0.4286\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.7774 - acc: 0.0000e+00 - val_loss: 0.9159 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.1234 - acc: 0.0000e+00 - val_loss: 0.4146 - val_acc: 0.4286\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4390 - acc: 0.0000e+00 - val_loss: 0.0608 - val_acc: 0.4286\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0279 - acc: 0.0000e+00 - val_loss: 0.4003 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2344 - acc: 0.0000e+00 - val_loss: 0.7891 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4567 - acc: 0.0000e+00 - val_loss: 0.7449 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3552 - acc: 0.0000e+00 - val_loss: 0.3879 - val_acc: 0.0000e+00\n",
      "Train: C:\\machinelearning\\epochs\\epoch01_front.mkv\n",
      "Train on 57 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4035 - acc: 0.3860 - val_loss: 0.1674 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2508 - acc: 0.6140 - val_loss: 0.0337 - val_acc: 0.1429\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3171 - acc: 0.4035 - val_loss: 0.0470 - val_acc: 0.1429\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.3522 - acc: 0.4035 - val_loss: 0.0346 - val_acc: 0.1429\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2416 - acc: 0.4035 - val_loss: 0.0631 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1487 - acc: 0.7895 - val_loss: 0.1977 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1791 - acc: 0.4211 - val_loss: 0.3451 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2573 - acc: 0.3860 - val_loss: 0.3895 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2851 - acc: 0.3860 - val_loss: 0.3159 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2531 - acc: 0.3860 - val_loss: 0.1962 - val_acc: 0.0000e+00\n",
      "Train: C:\\machinelearning\\epochs\\epoch01_front.mkv\n",
      "Train on 57 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.0333 - acc: 0.0877 - val_loss: 0.2908 - val_acc: 0.1429\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.9766 - acc: 0.0877 - val_loss: 0.2769 - val_acc: 0.1429\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.9073 - acc: 0.0877 - val_loss: 0.3457 - val_acc: 0.1429\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.8534 - acc: 0.0877 - val_loss: 0.4791 - val_acc: 0.1429\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.8542 - acc: 0.0877 - val_loss: 0.6364 - val_acc: 0.1429\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.9046 - acc: 0.0877 - val_loss: 0.7617 - val_acc: 0.1429\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.9669 - acc: 0.0877 - val_loss: 0.8159 - val_acc: 0.1429\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.0077 - acc: 0.0877 - val_loss: 0.7943 - val_acc: 0.1429\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.0164 - acc: 0.0877 - val_loss: 0.7207 - val_acc: 0.1429\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.0015 - acc: 0.0877 - val_loss: 0.6289 - val_acc: 0.1429\n",
      "Train: C:\\machinelearning\\epochs\\epoch01_front.mkv\n",
      "Train on 57 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.1673 - acc: 0.4386 - val_loss: 0.3229 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.9952 - acc: 0.4386 - val_loss: 0.6696 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 3ms/step - loss: 0.8002 - acc: 0.1053 - val_loss: 1.2086 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.7130 - acc: 0.0877 - val_loss: 1.7588 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.7161 - acc: 0.0877 - val_loss: 2.0500 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.7035 - acc: 0.0877 - val_loss: 1.9605 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.6368 - acc: 0.0877 - val_loss: 1.6144 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5771 - acc: 0.0877 - val_loss: 1.2276 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.5804 - acc: 0.0877 - val_loss: 0.9395 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.6337 - acc: 0.3158 - val_loss: 0.7876 - val_acc: 0.0000e+00\n",
      "Train: C:\\machinelearning\\epochs\\epoch01_front.mkv\n",
      "Train on 57 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1392 - acc: 0.1930 - val_loss: 0.2274 - val_acc: 0.5714\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1201 - acc: 0.1930 - val_loss: 0.1497 - val_acc: 0.5714\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1263 - acc: 0.1930 - val_loss: 0.1156 - val_acc: 0.5714\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1353 - acc: 0.1930 - val_loss: 0.1105 - val_acc: 0.5714\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1321 - acc: 0.1930 - val_loss: 0.1274 - val_acc: 0.5714\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1192 - acc: 0.1930 - val_loss: 0.1642 - val_acc: 0.5714\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1083 - acc: 0.1930 - val_loss: 0.2150 - val_acc: 0.5714\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1075 - acc: 0.1930 - val_loss: 0.2651 - val_acc: 0.5714\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1148 - acc: 0.1930 - val_loss: 0.2968 - val_acc: 0.5714\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1219 - acc: 0.1930 - val_loss: 0.3002 - val_acc: 0.5714\n",
      "Train: C:\\machinelearning\\epochs\\epoch01_front.mkv\n",
      "Train on 25 samples, validate on 3 samples\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6196 - acc: 0.1600 - val_loss: 0.5719 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5791 - acc: 0.1600 - val_loss: 0.6681 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5092 - acc: 0.1600 - val_loss: 0.8092 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4285 - acc: 0.1600 - val_loss: 0.9890 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3544 - acc: 0.1600 - val_loss: 1.1984 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2985 - acc: 0.0000e+00 - val_loss: 1.4262 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2659 - acc: 0.0000e+00 - val_loss: 1.6562 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2556 - acc: 0.0800 - val_loss: 1.8725 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2626 - acc: 0.3200 - val_loss: 2.0633 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2801 - acc: 0.3600 - val_loss: 2.2184 - val_acc: 0.0000e+00\n",
      "Train: C:\\machinelearning\\epochs\\epoch01_front.mkv\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "#训练模型\n",
    "from keras import optimizers\n",
    "import h5py\n",
    "\n",
    "img_path = params.data_dir\n",
    "batch_size = 64\n",
    "input_shape=(params.FLAGS.img_w, params.FLAGS.img_h, params.FLAGS.img_c)\n",
    "model = nvidia_model2(input_shape=input_shape)\n",
    "sgd = optimizers.SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "adam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "               optimizer=adam,\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "for epochid in ['01']:\n",
    "    imggen = ImgGenerator(img_path=img_path,\n",
    "                     batch_id=epochid,\n",
    "                     batch_size=batch_size,\n",
    "                     input_shape=input_shape)\n",
    "    while True:\n",
    "        x_train,y_train,x_valid,y_valid = imggen.next_batch()\n",
    "      \n",
    "        if(len(x_train) == 0):\n",
    "            break\n",
    "        model.fit(x_train, y_train,epochs=10,batch_size=32,validation_data=(x_valid, y_valid),shuffle=True)\n",
    "    \n",
    "utils.save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: C:\\machinelearning\\epochs\\epoch10_front.mkv\n",
      "Model already exists, do you want to reuse? (y/n): y\n",
      "Model fetched from the disk\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_5 (Lambda)            (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 30, 30, 24)        1824      \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 13, 13, 36)        21636     \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 5, 5, 48)          43248     \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 3, 3, 64)          27712     \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 1, 1, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1164)              75660     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               116500    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 329,079\n",
      "Trainable params: 329,079\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[[ 5.40371275]\n",
      " [ 5.40195274]\n",
      " [ 5.41096115]\n",
      " [ 5.405406  ]\n",
      " [ 5.40658045]\n",
      " [ 5.39900303]\n",
      " [ 5.40677691]\n",
      " [ 5.40726566]\n",
      " [ 5.40494156]\n",
      " [ 5.40049124]\n",
      " [ 5.40194321]\n",
      " [ 5.39860535]\n",
      " [ 5.39332199]\n",
      " [ 5.3989687 ]\n",
      " [ 5.39428616]\n",
      " [ 5.391078  ]\n",
      " [ 5.39076233]\n",
      " [ 5.39166212]\n",
      " [ 5.38627052]\n",
      " [ 5.38623571]\n",
      " [ 5.38250685]\n",
      " [ 5.37787342]\n",
      " [ 5.3782053 ]\n",
      " [ 5.38692474]\n",
      " [ 5.37741756]\n",
      " [ 5.37708855]\n",
      " [ 5.36551666]\n",
      " [ 5.36503839]\n",
      " [ 5.36838055]\n",
      " [ 5.37694263]\n",
      " [ 5.3731823 ]\n",
      " [ 5.3771081 ]\n",
      " [ 5.36804771]\n",
      " [ 5.36912394]\n",
      " [ 5.36800766]\n",
      " [ 5.38102913]\n",
      " [ 5.37893009]\n",
      " [ 5.37753677]\n",
      " [ 5.3871212 ]\n",
      " [ 5.38564444]\n",
      " [ 5.38149738]\n",
      " [ 5.38433599]\n",
      " [ 5.38046265]\n",
      " [ 5.3811655 ]\n",
      " [ 5.38290071]\n",
      " [ 5.38361311]\n",
      " [ 5.38927984]\n",
      " [ 5.38981056]\n",
      " [ 5.39001083]\n",
      " [ 5.388484  ]\n",
      " [ 5.3880291 ]\n",
      " [ 5.38494539]\n",
      " [ 5.38180351]\n",
      " [ 5.37725592]\n",
      " [ 5.38110065]\n",
      " [ 5.38587999]\n",
      " [ 5.38569641]] [[-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-1. ]\n",
      " [-1. ]\n",
      " [-1. ]\n",
      " [-1. ]\n",
      " [-1. ]\n",
      " [-1. ]\n",
      " [-1. ]\n",
      " [-1. ]\n",
      " [-1. ]\n",
      " [-1. ]\n",
      " [-1. ]\n",
      " [-1.5]\n",
      " [-1.5]\n",
      " [-1.5]\n",
      " [-1.5]\n",
      " [-1.5]\n",
      " [-1.5]\n",
      " [-1.5]\n",
      " [-1.5]\n",
      " [-1.5]]\n",
      "Score: -266.645369433\n"
     ]
    }
   ],
   "source": [
    "#测试模型\n",
    "import params\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "img_path = params.data_dir\n",
    "input_shape=(params.FLAGS.img_w, params.FLAGS.img_h, params.FLAGS.img_c)\n",
    "x_test,y_test,_,_ = ImgGenerator(img_path,'10',batch_size=64,input_shape=input_shape).next_batch()\n",
    "\n",
    "\n",
    "model = utils.get_model()\n",
    "y_predict = model.predict(x_test)\n",
    "print(y_predict,y_test)\n",
    "score = r2_score(y_test,y_predict)\n",
    "print('Score:',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "rows = pd.read_csv('C:/machinelearning/0130/deep.csv')\n",
    "y1=list(rows.Loss.values)\n",
    "x1=range(0,len(y1)) \n",
    "y2=list(rows.ValLoss.values)\n",
    "x2=range(0,len(y2)) \n",
    "plt.plot(x1,y1,label='Loss') \n",
    "plt.plot(x2,y2,label='Val Loss') \n",
    "plt.xlabel('epochs Number') \n",
    "plt.ylabel('Loss') \n",
    "plt.title('0130') \n",
    "plt.legend() \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nvidia_model 视频01 epochs10  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
