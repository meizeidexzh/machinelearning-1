{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangyi/anaconda2/envs/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: /Users/yangyi/Downloads/machinelearning/epochs/epoch01_front.mkv\n",
      "Shape:x = (10, 64, 64, 3) y = (10, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Angle:[-1.5]')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110a67c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import params,utils\n",
    "\n",
    "#按批次读取数据\n",
    "class VidDataGenerator():\n",
    "    def __init__(self,img_path,batch_id,batch_size=None,input_shape=(224,224,3),train_ratio=1):\n",
    "        self.img_path = img_path\n",
    "        self.batch_id = batch_id\n",
    "        self.batch_size = batch_size\n",
    "        self.current_frame = 0\n",
    "        self.input_shape = input_shape\n",
    "        self.train_ratio = train_ratio\n",
    "        self.vid_path = utils.join_dir(params.data_dir, 'epoch{:0>2}_front.mkv'.format(self.batch_id))\n",
    "        print('Training:',self.vid_path)\n",
    "        \n",
    "    def next_batch(self):\n",
    "        #标注处理\n",
    "        label_all = utils.get_human_steering(self.batch_id)\n",
    "        if(self.batch_size == None):\n",
    "            self.batch_size = len(label_all)\n",
    "            \n",
    "        label = utils.get_human_steering(self.batch_id)[self.current_frame:self.current_frame+self.batch_size]\n",
    "        labels = [[label[i]] for i in range(len(label))]\n",
    "        labels = np.array(labels)\n",
    "        #图像处理        \n",
    "        \n",
    "        cap = cv2.VideoCapture(self.vid_path)\n",
    "        nframe = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) - 2)\n",
    "        if( (self.current_frame+self.batch_size) > nframe):\n",
    "            self.batch_size = nframe - self.current_frame\n",
    "        images = []\n",
    "        for i in range(self.current_frame,self.current_frame+self.batch_size):\n",
    "            utils.cv2_goto_frame(cap,i) \n",
    "            ret, frame = cap.read()\n",
    "            if (ret == True):\n",
    "                shape = frame.shape\n",
    "                frame = frame[int(shape[0]/3):shape[0]-150, 0:shape[1]]\n",
    "                frame = cv2.resize(frame, (self.input_shape[0], self.input_shape[1]), interpolation=cv2.INTER_AREA)\n",
    "                frame = np.resize(frame, (self.input_shape[0], self.input_shape[1], self.input_shape[2]))\n",
    "                images.append(frame)\n",
    "                del frame\n",
    "        images = np.array(images)    \n",
    "        self.current_frame = utils.cv2_current_frame(cap)\n",
    "        cap.release()\n",
    "\n",
    "        return (images[:int(self.batch_size*self.train_ratio)],labels[:int(self.batch_size*self.train_ratio)],\n",
    "                images[int(self.batch_size*self.train_ratio):],labels[int(self.batch_size*self.train_ratio):])\n",
    "    \n",
    "#Test\n",
    "from matplotlib import pyplot \n",
    "%matplotlib inline\n",
    "img_path = params.data_dir\n",
    "input_shape=(64, 64, params.FLAGS.img_c)\n",
    "x_test,y_test,_,_ = VidDataGenerator(img_path,'01',batch_size=10,input_shape=input_shape).next_batch()\n",
    "assert len(x_test)==len(y_test)\n",
    "index = 9\n",
    "print('Shape:x =',x_test.shape,'y =',y_test.shape)\n",
    "pyplot.imshow(x_test[index])\n",
    "pyplot.title('Angle:'+str(y_test[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成器\n",
    "def train_generator(img_path,epochs):\n",
    "    for i in epochs:\n",
    "        try:\n",
    "            file_name = utils.join_dir(img_path, 'epoch{:0>2}.pkl'.format(i))\n",
    "            with open(file_name,'rb') as fs:\n",
    "                x_train,y_train = pickle.load(fs)\n",
    "                yield x_train,y_train\n",
    "        except StopIteration as e:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yangyi/Downloads/machinelearning/epochs/epoch02.pkl Already exist\n"
     ]
    }
   ],
   "source": [
    "#生成测试文件\n",
    "import pickle\n",
    "import os\n",
    "def save_train_file():\n",
    "    img_path = params.data_dir\n",
    "    batch_size = None\n",
    "    input_shape=(params.FLAGS.img_w, params.FLAGS.img_h, params.FLAGS.img_c)\n",
    "    #for i in ['01','02','03','04','05','06','07','08','09','10']:\n",
    "    for i in ['02']:\n",
    "        file_name = utils.join_dir(img_path, 'epoch{:0>2}.pkl'.format(i))\n",
    "        if(os.path.exists(file_name)):\n",
    "            print(file_name,'Already exist')\n",
    "            break\n",
    "        train_data= VidDataGenerator(img_path=img_path,batch_id=i,batch_size=batch_size,input_shape=input_shape)\n",
    "        x_train,y_train,_,_ = train_data.next_batch()\n",
    "        \n",
    "        with open(file_name,'wb') as fs:\n",
    "            pickle.dump((x_train,y_train),fs)\n",
    "        print('Save '+ file_name)\n",
    "        \n",
    "save_train_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 64, 64, 3) (1500, 1)\n"
     ]
    }
   ],
   "source": [
    "file_name = utils.join_dir(img_path, 'epoch{:0>2}.pkl'.format('01'))\n",
    "with open(file_name,'rb') as fs:\n",
    "    x_train,y_train = pickle.load(fs)\n",
    "print(x_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgg16模型改造\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Input\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.layers import Lambda\n",
    "\n",
    "def vgg16_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    lambda_input = Lambda(lambda x:x/255.-0.5,name='Lambda')(inputs)\n",
    "    base_model = VGG16(include_top=False, weights='imagenet',input_tensor=lambda_input)\n",
    "    \n",
    "    #for layer in base_model.layers:\n",
    "    #    layer.trainable = False\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(512, activation='relu', name='fc1')(x)\n",
    "    x = Dropout(0.8,name='fc1_dropout')(x)\n",
    "    x = Dense(256, activation='relu', name='fc2')(x)\n",
    "    x = Dropout(0.8,name='fc2_dropout')(x)\n",
    "    x = Dense(64, activation='relu', name='fc3')(x)\n",
    "    x = Dropout(0.8,name='fc3_dropout')(x)\n",
    "    x = Dense(1,activation='tanh',name='output')(x)\n",
    "    \n",
    "    model = Model(inputs,x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input,Conv2D,Lambda,MaxPooling2D,Flatten,Dense\n",
    "def nvidia_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    x = Lambda(lambda x:x/255.,name='Lambda')(inputs)\n",
    "    \n",
    "    x = Conv2D(24, (5, 5), activation='relu', padding='same', name='block1_conv1')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    x = Conv2D(36, (5, 5), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "    \n",
    "    x = Conv2D(48, (5, 5), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "    \n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(1164, activation='relu', name='fc1')(x)\n",
    "    x = Dense(100, activation='relu', name='fc2')(x)\n",
    "    x = Dense(50, activation='relu', name='fc3')(x)\n",
    "    x = Dense(10, activation='relu', name='fc4')(x)\n",
    "    x = Dense(1,name='output')(x)\n",
    "    \n",
    "    model = Model(inputs,x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Convolution2D\n",
    "from keras.models import Sequential\n",
    "def nvidia_model2(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x:x/255, input_shape=input_shape))\n",
    "    model.add(Convolution2D(24,5,5,border_mode='valid', activation='relu', subsample=(2,2)))\n",
    "    model.add(Convolution2D(36,5,5,border_mode='valid', activation='relu', subsample=(2,2)))\n",
    "    model.add(Convolution2D(48,5,5,border_mode='valid', activation='relu', subsample=(2,2)))\n",
    "    model.add(Convolution2D(64,3,3,border_mode='valid', activation='relu', subsample=(1,1)))\n",
    "    model.add(Convolution2D(64,3,3,border_mode='valid', activation='relu', subsample=(1,1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1164, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "Lambda (Lambda)              (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 24)        1824      \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 24)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 36)        21636     \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 36)        0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 48)        43248     \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 48)          0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 64)          27712     \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1164)              299148    \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 100)               116500    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 552,567\n",
      "Trainable params: 552,567\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " 1/10 [==>...........................] - ETA: 1:41 - loss: 11.1857 - acc: 0.0633"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-7d782a74b0bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m model.fit_generator(train_generator(img_path,['01']),\n\u001b[1;32m     19\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                     epochs=10)\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/tensorflow/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2143\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2144\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2145\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2147\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tensorflow/lib/python3.5/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    760\u001b[0m                 \u001b[0mall_finished\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall_finished\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#训练模型\n",
    "from keras import optimizers\n",
    "import h5py\n",
    "\n",
    "img_path = params.data_dir\n",
    "batch_size = None\n",
    "input_shape=(params.FLAGS.img_w, params.FLAGS.img_h, params.FLAGS.img_c)\n",
    "model = nvidia_model(input_shape=input_shape)\n",
    "sgd = optimizers.SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "adam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "               optimizer=adam,\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit_generator(train_generator(img_path,['01']),\n",
    "                    steps_per_epoch=10,\n",
    "                    epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "Lambda (Lambda)              (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "fc1_dropout (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "fc2_dropout (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "fc3_dropout (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 15,911,617\n",
      "Trainable params: 15,911,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training: /Users/yangyi/Downloads/machinelearning/epochs/epoch01_front.mkv\n",
      "Train on 1350 samples, validate on 150 samples\n",
      "Epoch 1/10\n",
      "1350/1350 [==============================] - 160s 119ms/step - loss: 11.2742 - acc: 0.0548 - val_loss: 10.6817 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1350/1350 [==============================] - 158s 117ms/step - loss: 11.2648 - acc: 0.0593 - val_loss: 10.6817 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1350/1350 [==============================] - 156s 116ms/step - loss: 11.0878 - acc: 0.0600 - val_loss: 10.6817 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1350/1350 [==============================] - 160s 119ms/step - loss: 11.5870 - acc: 0.0615 - val_loss: 10.6817 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1350/1350 [==============================] - 152s 113ms/step - loss: 10.9427 - acc: 0.0607 - val_loss: 10.6817 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1350/1350 [==============================] - 152s 113ms/step - loss: 10.9419 - acc: 0.0593 - val_loss: 10.6817 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1350/1350 [==============================] - 152s 112ms/step - loss: 11.3581 - acc: 0.0533 - val_loss: 10.6817 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1350/1350 [==============================] - 156s 116ms/step - loss: 11.3344 - acc: 0.0548 - val_loss: 10.6817 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1350/1350 [==============================] - 364s 269ms/step - loss: 11.5093 - acc: 0.0511 - val_loss: 10.6817 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1350/1350 [==============================] - 192s 142ms/step - loss: 11.2011 - acc: 0.0556 - val_loss: 10.6817 - val_acc: 0.0000e+00\n",
      "Training: /Users/yangyi/Downloads/machinelearning/epochs/epoch02_front.mkv\n",
      "Train on 3510 samples, validate on 390 samples\n",
      "Epoch 1/10\n",
      "3510/3510 [==============================] - 528s 150ms/step - loss: 4.7541 - acc: 0.0772 - val_loss: 10.8147 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "3510/3510 [==============================] - 513s 146ms/step - loss: 4.5754 - acc: 0.0752 - val_loss: 10.8147 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      " 608/3510 [====>.........................] - ETA: 7:17 - loss: 4.3853 - acc: 0.0872"
     ]
    }
   ],
   "source": [
    "#训练模型\n",
    "from keras import optimizers\n",
    "import h5py\n",
    "\n",
    "img_path = params.data_dir\n",
    "batch_size = None\n",
    "input_shape=(params.FLAGS.img_w, params.FLAGS.img_h, params.FLAGS.img_c)\n",
    "model = nvidia_model(input_shape=input_shape)\n",
    "sgd = optimizers.SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "adam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "               optimizer=adam,\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "with open(utils.join_dir(img_path, 'epoch{:0>2}.p'.format('09')),'rb') as fs:\n",
    "        x_valid,y_valid = pickle.load(fs)\n",
    "        \n",
    "for epochid in ['01','02','03','04','05','06','07','08']:\n",
    "    file_name = utils.join_dir(img_path, 'epoch{:0>2}.p'.format(epochid))\n",
    "    with open(file_name,'rb') as fs:\n",
    "        x_train,y_train = pickle.load(fs)\n",
    "        if(len(x_train) == 0):\n",
    "            break\n",
    "        model.fit(x_train, y_train,epochs=10,batch_size=128,validation_data=(x_valid,y_valid),shuffle=True)\n",
    "    \n",
    "utils.save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: /Users/yangyi/Downloads/machinelearning/epochs/epoch10_front.mkv\n",
      "Model already exists, do you want to reuse? (y/n): y\n",
      "Model fetched from the disk\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_1 (Lambda)            (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 24)        1824      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 36)        21636     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 5, 48)          43248     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 3, 64)          27712     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 1, 1, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1164)              75660     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               116500    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 329,079\n",
      "Trainable params: 329,079\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Score: -16.125919526124836\n"
     ]
    }
   ],
   "source": [
    "#测试模型\n",
    "import params,utils\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "img_path = params.data_dir\n",
    "input_shape=(params.FLAGS.img_w, params.FLAGS.img_h, params.FLAGS.img_c)\n",
    "x_test,y_test,_,_ = VidDataGenerator(img_path,'10',batch_size=64,input_shape=input_shape).next_batch()\n",
    "\n",
    "\n",
    "model = utils.get_model()\n",
    "y_predict = model.predict(x_test)\n",
    "#print(y_predict,y_test)\n",
    "score = r2_score(y_test,y_predict)\n",
    "print('Score:',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "rows = pd.read_csv('C:/machinelearning/0130/deep.csv')\n",
    "y1=list(rows.Loss.values)\n",
    "x1=range(0,len(y1)) \n",
    "y2=list(rows.ValLoss.values)\n",
    "x2=range(0,len(y2)) \n",
    "plt.plot(x1,y1,label='Loss') \n",
    "plt.plot(x2,y2,label='Val Loss') \n",
    "plt.xlabel('epochs Number') \n",
    "plt.ylabel('Loss') \n",
    "plt.title('0130') \n",
    "plt.legend() \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nvidia_model 视频01 epochs10  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
