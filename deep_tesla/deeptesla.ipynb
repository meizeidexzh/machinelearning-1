{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: C:\\machinelearning\\epochs\\epoch01_front.mkv\n",
      "Shape:x = (10, 64, 64, 3) y = (10, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1c04d9179e8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niM0fCFQU/x/9Tn6dt0761wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c04b155748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import params,utils\n",
    "\n",
    "#按批次读取数据\n",
    "class VidDataGenerator():\n",
    "    def __init__(self,img_path,batch_id,batch_size=None,input_shape=(224,224,3),train_ratio=1):\n",
    "        self.img_path = img_path\n",
    "        self.batch_id = batch_id\n",
    "        self.batch_size = batch_size\n",
    "        self.current_frame = 0\n",
    "        self.input_shape = input_shape\n",
    "        self.train_ratio = train_ratio\n",
    "        self.vid_path = utils.join_dir(params.data_dir, 'epoch{:0>2}_front.mkv'.format(self.batch_id))\n",
    "        print('Training:',self.vid_path)\n",
    "        \n",
    "    def next_batch(self):\n",
    "        #标注处理\n",
    "        label_all = utils.get_human_steering(self.batch_id)\n",
    "        if(self.batch_size == None):\n",
    "            self.batch_size = len(label_all)\n",
    "            \n",
    "        label = utils.get_human_steering(self.batch_id)[self.current_frame:self.current_frame+self.batch_size]\n",
    "        labels = [[label[i]] for i in range(len(label))]\n",
    "        labels = np.array(labels)\n",
    "        #图像处理        \n",
    "        \n",
    "        cap = cv2.VideoCapture(self.vid_path)\n",
    "        nframe = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) - 2)\n",
    "        if( (self.current_frame+self.batch_size) > nframe):\n",
    "            self.batch_size = nframe - self.current_frame\n",
    "        images = []\n",
    "        for i in range(self.current_frame,self.current_frame+self.batch_size):\n",
    "            utils.cv2_goto_frame(cap,i) \n",
    "            ret, frame = cap.read()\n",
    "            if (ret == True):\n",
    "                shape = frame.shape\n",
    "                frame = frame[int(shape[0]/3):shape[0]-150, 0:shape[1]]\n",
    "                frame = cv2.resize(frame, (self.input_shape[0], self.input_shape[1]), interpolation=cv2.INTER_AREA)\n",
    "                frame = np.resize(frame, (self.input_shape[0], self.input_shape[1], self.input_shape[2]))\n",
    "                images.append(frame)\n",
    "                del frame\n",
    "        images = np.array(images)    \n",
    "        self.current_frame = utils.cv2_current_frame(cap)\n",
    "        cap.release()\n",
    "\n",
    "        return (images[:int(self.batch_size*self.train_ratio)],labels[:int(self.batch_size*self.train_ratio)],\n",
    "                images[int(self.batch_size*self.train_ratio):],labels[int(self.batch_size*self.train_ratio):])\n",
    "    \n",
    "#Test\n",
    "from matplotlib import pyplot \n",
    "%matplotlib inline\n",
    "img_path = params.data_dir\n",
    "input_shape=(64, 64, params.FLAGS.img_c)\n",
    "x_test,y_test,_,_ = VidDataGenerator(img_path,'01',batch_size=10,input_shape=input_shape).next_batch()\n",
    "assert len(x_test)==len(y_test)\n",
    "index = 8\n",
    "print('Shape:x =',x_test.shape,'y =',y_test.shape)\n",
    "pyplot.imshow(x_test[index])\n",
    "pyplot.title('Angle:'+str(y_test[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成器\n",
    "def train_generator(img_path,epochs):\n",
    "    for i in epochs:\n",
    "        try:\n",
    "            file_name = utils.join_dir(img_path, 'epoch{:0>2}.p'.format(i))\n",
    "            with open(file_name,'rb') as fs:\n",
    "                x_train,y_train = pickle.load(fs)\n",
    "            yield x_train,y_train\n",
    "        except StopIteration as e:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\machinelearning\\epochs\\epoch02.p Already exist\n"
     ]
    }
   ],
   "source": [
    "#生成测试文件\n",
    "import pickle\n",
    "import os\n",
    "def save_train_file():\n",
    "    img_path = params.data_dir\n",
    "    batch_size = None\n",
    "    input_shape=(params.FLAGS.img_w, params.FLAGS.img_h, params.FLAGS.img_c)\n",
    "    #for i in ['01','02','03','04','05','06','07','08','09','10']:\n",
    "    for i in ['02']:\n",
    "        file_name = utils.join_dir(img_path, 'epoch{:0>2}.p'.format(i))\n",
    "        if(os.path.exists(file_name)):\n",
    "            print(file_name,'Already exist')\n",
    "            break\n",
    "        train_data= VidDataGenerator(img_path=img_path,batch_id=i,batch_size=batch_size,input_shape=input_shape)\n",
    "        x_train,y_train,_,_ = train_data.next_batch()\n",
    "        \n",
    "        with open(file_name,'wb') as fs:\n",
    "            pickle.dump((x_train,y_train),fs)\n",
    "        print('Save '+ file_name)\n",
    "        \n",
    "save_train_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3900, 64, 64, 3) (3900, 1)\n"
     ]
    }
   ],
   "source": [
    "file_name = utils.join_dir(img_path, 'epoch{:0>2}.p'.format('02'))\n",
    "with open(file_name,'rb') as fs:\n",
    "    x_train,y_train = pickle.load(fs)\n",
    "print(x_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#vgg16模型改造\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Input\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.layers import Lambda\n",
    "\n",
    "def vgg16_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    lambda_input = Lambda(lambda x:x/255.-0.5,name='Lambda')(inputs)\n",
    "    base_model = VGG16(include_top=False, weights='imagenet',input_tensor=lambda_input)\n",
    "    \n",
    "    #for layer in base_model.layers:\n",
    "    #    layer.trainable = False\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(512, activation='relu', name='fc1')(x)\n",
    "    x = Dropout(0.8,name='fc1_dropout')(x)\n",
    "    x = Dense(256, activation='relu', name='fc2')(x)\n",
    "    x = Dropout(0.8,name='fc2_dropout')(x)\n",
    "    x = Dense(64, activation='relu', name='fc3')(x)\n",
    "    x = Dropout(0.8,name='fc3_dropout')(x)\n",
    "    x = Dense(1,activation='tanh',name='output')(x)\n",
    "    \n",
    "    model = Model(inputs,x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input,Conv2D,Lambda,MaxPooling2D,Flatten,Dense\n",
    "def nvidia_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    x = Lambda(lambda x:x/255.,name='Lambda')(inputs)\n",
    "    \n",
    "    x = Conv2D(24, (5, 5), activation='relu', padding='same', name='block1_conv1')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    x = Conv2D(36, (5, 5), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "    \n",
    "    x = Conv2D(48, (5, 5), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "    \n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(1164, activation='relu', name='fc1')(x)\n",
    "    x = Dense(100, activation='relu', name='fc2')(x)\n",
    "    x = Dense(50, activation='relu', name='fc3')(x)\n",
    "    x = Dense(10, activation='relu', name='fc4')(x)\n",
    "    x = Dense(1,name='output')(x)\n",
    "    \n",
    "    model = Model(inputs,x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Convolution2D\n",
    "from keras.models import Sequential\n",
    "def nvidia_model2(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x:x/255, input_shape=input_shape))\n",
    "    model.add(Convolution2D(24,5,5,border_mode='valid', activation='relu', subsample=(2,2)))\n",
    "    model.add(Convolution2D(36,5,5,border_mode='valid', activation='relu', subsample=(2,2)))\n",
    "    model.add(Convolution2D(48,5,5,border_mode='valid', activation='relu', subsample=(2,2)))\n",
    "    model.add(Convolution2D(64,3,3,border_mode='valid', activation='relu', subsample=(1,1)))\n",
    "    model.add(Convolution2D(64,3,3,border_mode='valid', activation='relu', subsample=(1,1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1164, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "Lambda (Lambda)              (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 24)        1824      \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 24)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 36)        21636     \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 36)        0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 48)        43248     \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 48)          0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 64)          27712     \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1164)              299148    \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 100)               116500    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 552,567\n",
      "Trainable params: 552,567\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "#训练模型\n",
    "from keras import optimizers\n",
    "import h5py\n",
    "\n",
    "img_path = params.data_dir\n",
    "batch_size = None\n",
    "input_shape=(params.FLAGS.img_w, params.FLAGS.img_h, params.FLAGS.img_c)\n",
    "model = nvidia_model(input_shape=input_shape)\n",
    "sgd = optimizers.SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "adam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "               optimizer=adam,\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit_generator(train_generator(img_path,['02']),\n",
    "                    steps_per_epoch=10,\n",
    "                    epochs=10,\n",
    "                    validation_data=train_generator(img_path,['01']),\n",
    "                    validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "Lambda (Lambda)              (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 24)        1824      \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 24)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 36)        21636     \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 36)        0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 48)        43248     \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 48)          0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 64)          27712     \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1164)              299148    \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 100)               116500    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 552,567\n",
      "Trainable params: 552,567\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train: /Users/yangyi/Downloads/machinelearning/epochs/epoch01_front.mkv\n",
      "Train on 1350 samples, validate on 150 samples\n",
      "Epoch 1/10\n",
      "1350/1350 [==============================] - 10s 8ms/step - loss: 10.3240 - acc: 0.0704 - val_loss: 18.5299 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1350/1350 [==============================] - 10s 7ms/step - loss: 7.5909 - acc: 0.0719 - val_loss: 14.3886 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1350/1350 [==============================] - 10s 7ms/step - loss: 3.1228 - acc: 0.0681 - val_loss: 22.0377 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1350/1350 [==============================] - 10s 7ms/step - loss: 1.7615 - acc: 0.1089 - val_loss: 17.9098 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1350/1350 [==============================] - 10s 7ms/step - loss: 1.0520 - acc: 0.1644 - val_loss: 16.8782 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1350/1350 [==============================] - 10s 7ms/step - loss: 0.8033 - acc: 0.1556 - val_loss: 17.0773 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1350/1350 [==============================] - 10s 7ms/step - loss: 0.5898 - acc: 0.1659 - val_loss: 17.2705 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1350/1350 [==============================] - 10s 7ms/step - loss: 0.4841 - acc: 0.1807 - val_loss: 15.0282 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1350/1350 [==============================] - 10s 7ms/step - loss: 0.3500 - acc: 0.2170 - val_loss: 17.8874 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1350/1350 [==============================] - 10s 7ms/step - loss: 0.3511 - acc: 0.2119 - val_loss: 14.4760 - val_acc: 0.0000e+00\n",
      "Train: /Users/yangyi/Downloads/machinelearning/epochs/epoch01_front.mkv\n",
      "Train: /Users/yangyi/Downloads/machinelearning/epochs/epoch02_front.mkv\n",
      "Train on 3510 samples, validate on 390 samples\n",
      "Epoch 1/10\n",
      "3510/3510 [==============================] - 27s 8ms/step - loss: 1.7368 - acc: 0.1199 - val_loss: 1.6046 - val_acc: 0.1179\n",
      "Epoch 2/10\n",
      "3510/3510 [==============================] - 27s 8ms/step - loss: 0.5823 - acc: 0.1652 - val_loss: 2.4792 - val_acc: 0.0462\n",
      "Epoch 3/10\n",
      "3510/3510 [==============================] - 27s 8ms/step - loss: 0.3283 - acc: 0.2066 - val_loss: 2.3702 - val_acc: 0.0615\n",
      "Epoch 4/10\n",
      "3510/3510 [==============================] - 27s 8ms/step - loss: 0.2233 - acc: 0.2382 - val_loss: 2.3248 - val_acc: 0.1103\n",
      "Epoch 5/10\n",
      "3510/3510 [==============================] - 27s 8ms/step - loss: 0.1585 - acc: 0.2712 - val_loss: 2.4556 - val_acc: 0.1103\n",
      "Epoch 6/10\n",
      "3510/3510 [==============================] - 27s 8ms/step - loss: 0.1061 - acc: 0.2974 - val_loss: 2.6933 - val_acc: 0.1179\n",
      "Epoch 7/10\n",
      "3510/3510 [==============================] - 27s 8ms/step - loss: 0.0855 - acc: 0.3108 - val_loss: 2.6291 - val_acc: 0.1026\n",
      "Epoch 8/10\n",
      "3510/3510 [==============================] - 27s 8ms/step - loss: 0.0773 - acc: 0.3202 - val_loss: 3.3657 - val_acc: 0.0359\n",
      "Epoch 9/10\n",
      "3510/3510 [==============================] - 27s 8ms/step - loss: 0.0735 - acc: 0.3259 - val_loss: 2.9130 - val_acc: 0.0718\n",
      "Epoch 10/10\n",
      "3510/3510 [==============================] - 27s 8ms/step - loss: 0.0629 - acc: 0.3330 - val_loss: 3.4974 - val_acc: 0.0359\n",
      "Train: /Users/yangyi/Downloads/machinelearning/epochs/epoch02_front.mkv\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "#训练模型\n",
    "from keras import optimizers\n",
    "import h5py\n",
    "\n",
    "img_path = params.data_dir\n",
    "batch_size = None\n",
    "input_shape=(params.FLAGS.img_w, params.FLAGS.img_h, params.FLAGS.img_c)\n",
    "model = nvidia_model(input_shape=input_shape)\n",
    "sgd = optimizers.SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "adam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "               optimizer=adam,\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "for epochid in ['01','02']:\n",
    "    imggen = VidDataGenerator(img_path=img_path,\n",
    "                     batch_id=epochid,\n",
    "                     batch_size=batch_size,\n",
    "                     input_shape=input_shape)\n",
    "    while True:\n",
    "        x_train,y_train,x_valid,y_valid = imggen.next_batch()\n",
    "      \n",
    "        if(len(x_train) == 0):\n",
    "            break\n",
    "        model.fit(x_train, y_train,epochs=10,batch_size=32,validation_data=(x_valid, y_valid),shuffle=True)\n",
    "    \n",
    "utils.save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: /Users/yangyi/Downloads/machinelearning/epochs/epoch10_front.mkv\n",
      "Model already exists, do you want to reuse? (y/n): y\n",
      "Model fetched from the disk\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "Lambda (Lambda)              (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 24)        1824      \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 24)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 36)        21636     \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 36)        0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 48)        43248     \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 48)          0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 64)          27712     \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1164)              299148    \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 100)               116500    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 552,567\n",
      "Trainable params: 552,567\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[[0.7637197 ]\n",
      " [0.73529994]\n",
      " [0.6803616 ]\n",
      " [0.61636436]\n",
      " [0.58053434]\n",
      " [0.57675993]\n",
      " [0.56826985]\n",
      " [0.5753547 ]\n",
      " [0.5875536 ]\n",
      " [0.5752269 ]\n",
      " [0.517702  ]\n",
      " [0.45083034]\n",
      " [0.36895835]\n",
      " [0.32968318]\n",
      " [0.3196758 ]\n",
      " [0.29971254]\n",
      " [0.29153   ]\n",
      " [0.28874004]\n",
      " [0.27387464]\n",
      " [0.2677728 ]\n",
      " [0.27678454]\n",
      " [0.28878486]\n",
      " [0.2765478 ]\n",
      " [0.22207844]\n",
      " [0.18925488]\n",
      " [0.21754229]\n",
      " [0.25522196]\n",
      " [0.2563187 ]\n",
      " [0.28706658]\n",
      " [0.30368936]\n",
      " [0.31202972]\n",
      " [0.30712354]\n",
      " [0.32278454]\n",
      " [0.29372108]\n",
      " [0.27101982]\n",
      " [0.27907503]\n",
      " [0.22460926]\n",
      " [0.146124  ]\n",
      " [0.09550392]\n",
      " [0.13698351]\n",
      " [0.19534814]\n",
      " [0.21472561]\n",
      " [0.26418245]\n",
      " [0.3109318 ]\n",
      " [0.32393944]\n",
      " [0.29849422]\n",
      " [0.27594435]\n",
      " [0.26490533]\n",
      " [0.24454606]\n",
      " [0.21032345]\n",
      " [0.18431175]\n",
      " [0.19662654]\n",
      " [0.21153057]\n",
      " [0.25246942]\n",
      " [0.23914516]\n",
      " [0.22857988]\n",
      " [0.22553432]] [[-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-1. ]\n",
      " [-1. ]\n",
      " [-1. ]\n",
      " [-1. ]\n",
      " [-1. ]\n",
      " [-1. ]\n",
      " [-1. ]\n",
      " [-1. ]\n",
      " [-1. ]\n",
      " [-1. ]\n",
      " [-1. ]\n",
      " [-1.5]\n",
      " [-1.5]\n",
      " [-1.5]\n",
      " [-1.5]\n",
      " [-1.5]\n",
      " [-1.5]\n",
      " [-1.5]\n",
      " [-1.5]\n",
      " [-1.5]]\n",
      "Score: -8.095033719529257\n"
     ]
    }
   ],
   "source": [
    "#测试模型\n",
    "import params,utils\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "img_path = params.data_dir\n",
    "input_shape=(params.FLAGS.img_w, params.FLAGS.img_h, params.FLAGS.img_c)\n",
    "x_test,y_test,_,_ = ImgGenerator(img_path,'10',batch_size=64,input_shape=input_shape).next_batch()\n",
    "\n",
    "\n",
    "model = utils.get_model()\n",
    "y_predict = model.predict(x_test)\n",
    "print(y_predict,y_test)\n",
    "score = r2_score(y_test,y_predict)\n",
    "print('Score:',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "rows = pd.read_csv('C:/machinelearning/0130/deep.csv')\n",
    "y1=list(rows.Loss.values)\n",
    "x1=range(0,len(y1)) \n",
    "y2=list(rows.ValLoss.values)\n",
    "x2=range(0,len(y2)) \n",
    "plt.plot(x1,y1,label='Loss') \n",
    "plt.plot(x2,y2,label='Val Loss') \n",
    "plt.xlabel('epochs Number') \n",
    "plt.ylabel('Loss') \n",
    "plt.title('0130') \n",
    "plt.legend() \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nvidia_model 视频01 epochs10  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
